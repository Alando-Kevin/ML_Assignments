{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Question 10; `Part (a)-(g)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INITIALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>Bad</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>Good</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120       Bad   42   \n",
       "1  11.22        111      48           16         260     83      Good   65   \n",
       "2  10.06        113      35           10         269     80    Medium   59   \n",
       "\n",
       "   Education Urban   US  \n",
       "0         17   Yes  Yes  \n",
       "1         10   Yes  Yes  \n",
       "2         12   Yes  Yes  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm \n",
    "\n",
    "carseats_data = pd.read_csv(r\"C:\\Users\\kevin\\OneDrive\\Desktop\\Strathmore\\Classes\\December 2024\\Machine Learning\\Assignments\\Data\\ALL CSV FILES - 2nd Edition\\Carseats.csv\")\n",
    "\n",
    "print(carseats_data.shape)\n",
    "\n",
    "carseats_data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Fit a multiple regression model to predict Sales using Price, Urban, and US**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.239\n",
      "Model:                            OLS   Adj. R-squared:                  0.234\n",
      "Method:                 Least Squares   F-statistic:                     41.52\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):           2.39e-23\n",
      "Time:                        03:56:32   Log-Likelihood:                -927.66\n",
      "No. Observations:                 400   AIC:                             1863.\n",
      "Df Residuals:                     396   BIC:                             1879.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         13.0435      0.651     20.036      0.000      11.764      14.323\n",
      "Price         -0.0545      0.005    -10.389      0.000      -0.065      -0.044\n",
      "Urban_Yes     -0.0219      0.272     -0.081      0.936      -0.556       0.512\n",
      "US_Yes         1.2006      0.259      4.635      0.000       0.691       1.710\n",
      "==============================================================================\n",
      "Omnibus:                        0.676   Durbin-Watson:                   1.912\n",
      "Prob(Omnibus):                  0.713   Jarque-Bera (JB):                0.758\n",
      "Skew:                           0.093   Prob(JB):                        0.684\n",
      "Kurtosis:                       2.897   Cond. No.                         628.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Set X and y\n",
    "X = carseats_data[['Price', 'Urban', 'US']]\n",
    "\n",
    "# Given that `urban` and `US` are categorical data, we transform that to dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X = X.astype(int)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = carseats_data['Sales']\n",
    "\n",
    "# Fit model and show summary\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Provide an interpretation of each coefficient in the model. Be careful some of the variables in the model are qualitative!**\n",
    "\n",
    "   \n",
    "***Intercept:*** *`13.0435`*\n",
    "- Represents the expected average sales when all predictors (Price, Urban_Yes, US_Yes) are zero. Since Price, Urban, and US cannot realistically be zero in this context, the intercept mainly serves as a baseline value for predictions.\n",
    "\n",
    "\n",
    "***Price*** *`-0.0545`*\n",
    "- *Interpretation:* For each unit increase in Price, the average sales decrease by `0.0545` units, holding all other variables constant.\n",
    "- *Significance:* The p-value for Price is `0.000` which is very small, indicating that price is *statistically significant* in explaining variations in sales.\n",
    "\n",
    "***Urban_Yes:*** *`-0.0219`*\n",
    "- *Interpretation:* If the store is located in an urban area (Urban_Yes = 1), the average sales decrease by `0.0219` units compared to stores in non-urban areas (Urban_Yes = 0), holding all other variables constant.\n",
    "- *Significance:* The p-value for Urban_Yes is `0.936`, which is much larger than the typical significance level of 0.05. This indicates that Urban_Yes is *not statistically significant* in predicting sales.\n",
    "\n",
    "***US_Yes:*** *`1.2006`*\n",
    "- *Interpretation:* If the store is located in the US (US_Yes = 1), the average sales increase by `1.2006` units compared to stores located outside the US (US_Yes = 0), holding all other variables constant.\n",
    "- *Significance:* The p-value for US_Yes is `0.000`, indicating that this variable is *highly statistically significant* in explaining variations in sales.\n",
    "\n",
    "***Overall Model Fit:***\n",
    "- The **`R-squared`** value of `0.239` indicates that `23.9%` of the variability in sales is explained by the model. While this suggests that the model has limited explanatory power, the significant predictors (Price and US_Yes) provide meaningful insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Write out the model in equation form, being careful to handle the qualitative variables properly.**\n",
    "\n",
    "-   *Sales = 13.0435 - 0.545(Price) - 0.0219(Urban_Yes) + 1.2006(US_Yes)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) For which of the predictors can you reject the null hypothesis H0 : #j = 0?**\n",
    "- Given the p-value we reject the null hypothesis for *Price* and *Urban* as they are very small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.239\n",
      "Model:                            OLS   Adj. R-squared:                  0.235\n",
      "Method:                 Least Squares   F-statistic:                     62.43\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):           2.66e-24\n",
      "Time:                        03:56:33   Log-Likelihood:                -927.66\n",
      "No. Observations:                 400   AIC:                             1861.\n",
      "Df Residuals:                     397   BIC:                             1873.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     13.0308      0.631     20.652      0.000      11.790      14.271\n",
      "US[T.Yes]      1.1996      0.258      4.641      0.000       0.692       1.708\n",
      "Price         -0.0545      0.005    -10.416      0.000      -0.065      -0.044\n",
      "==============================================================================\n",
      "Omnibus:                        0.666   Durbin-Watson:                   1.912\n",
      "Prob(Omnibus):                  0.717   Jarque-Bera (JB):                0.749\n",
      "Skew:                           0.092   Prob(JB):                        0.688\n",
      "Kurtosis:                       2.895   Cond. No.                         607.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Using statsmodel formula api for this part\n",
    "import statsmodels.formula.api as smf\n",
    "model1 = smf.ols(formula = 'Sales ~ Price + US', data=carseats_data)\n",
    "reg_model = model1.fit()\n",
    "print(reg_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f) How well do the models in (a) and (e) fit the data?**\n",
    "- Looking at the value of R-Squared both (a) and (e) have the same value `0.239`, we can conclude that neither model fit the data very well. However, (e) is a better model compared to (a) as it uses less variables for the same level of R-Squared "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g) Using the model from (e), obtain 95 % confidence intervals for the coefficient(s).**\n",
    "- For a 95% confidence interval, the range is calculated as:\n",
    "    - *Lower Bound: Coefficient - 2 x Standard Error*\n",
    "    - *Upper Bound: Coefficient + 2 x Standard Error*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Intervals:\n",
      "Intercept: [11.7688, 14.2928]\n",
      "US_Yes: [0.6836, 1.7156]\n",
      "Price: [-0.0645, -0.0445]\n"
     ]
    }
   ],
   "source": [
    "#Coefficients and Standard Errors\n",
    "coeff_stder = {\n",
    "    'Intercept': (13.0308, 0.631),\n",
    "    'US_Yes': (1.1996, 0.258),\n",
    "    'Price': (-0.0545, 0.005),\n",
    "}\n",
    "\n",
    "# Calculating confidence intervals\n",
    "def calc_ci(coef, stderr, confidence=0.95):\n",
    "    z_score = 2\n",
    "    lower = coef - z_score * stderr\n",
    "    upper = coef + z_score * stderr\n",
    "    return f\"[{lower:.4f}, {upper:.4f}]\"\n",
    "\n",
    "# Print output\n",
    "print(\"95% Confidence Intervals:\")\n",
    "for term, (coef, stderr) in coeff_stder.items():\n",
    "    interval = calc_ci(coef, stderr)\n",
    "    print(f\"{term}: {interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Question 13; `Part (a)-(d)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INITIALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import subplots\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_data = load_data('Weekly')\n",
    "weekly_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Produce some numerical and graphical summaries of the Weekly data. Do there appear to be any patterns?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Numerical Summaries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Direction\n",
       "Up      605\n",
       "Down    484\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_data['Direction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1089.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2000.048669</td>\n",
       "      <td>0.150585</td>\n",
       "      <td>0.151079</td>\n",
       "      <td>0.147205</td>\n",
       "      <td>0.145818</td>\n",
       "      <td>0.139893</td>\n",
       "      <td>1.574618</td>\n",
       "      <td>0.149899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.033182</td>\n",
       "      <td>2.357013</td>\n",
       "      <td>2.357254</td>\n",
       "      <td>2.360502</td>\n",
       "      <td>2.360279</td>\n",
       "      <td>2.361285</td>\n",
       "      <td>1.686636</td>\n",
       "      <td>2.356927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1990.000000</td>\n",
       "      <td>-18.195000</td>\n",
       "      <td>-18.195000</td>\n",
       "      <td>-18.195000</td>\n",
       "      <td>-18.195000</td>\n",
       "      <td>-18.195000</td>\n",
       "      <td>0.087465</td>\n",
       "      <td>-18.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1995.000000</td>\n",
       "      <td>-1.154000</td>\n",
       "      <td>-1.154000</td>\n",
       "      <td>-1.158000</td>\n",
       "      <td>-1.158000</td>\n",
       "      <td>-1.166000</td>\n",
       "      <td>0.332022</td>\n",
       "      <td>-1.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>1.002680</td>\n",
       "      <td>0.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>1.405000</td>\n",
       "      <td>1.409000</td>\n",
       "      <td>1.409000</td>\n",
       "      <td>1.409000</td>\n",
       "      <td>1.405000</td>\n",
       "      <td>2.053727</td>\n",
       "      <td>1.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>12.026000</td>\n",
       "      <td>12.026000</td>\n",
       "      <td>12.026000</td>\n",
       "      <td>12.026000</td>\n",
       "      <td>12.026000</td>\n",
       "      <td>9.328214</td>\n",
       "      <td>12.026000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year         Lag1         Lag2         Lag3         Lag4  \\\n",
       "count  1089.000000  1089.000000  1089.000000  1089.000000  1089.000000   \n",
       "mean   2000.048669     0.150585     0.151079     0.147205     0.145818   \n",
       "std       6.033182     2.357013     2.357254     2.360502     2.360279   \n",
       "min    1990.000000   -18.195000   -18.195000   -18.195000   -18.195000   \n",
       "25%    1995.000000    -1.154000    -1.154000    -1.158000    -1.158000   \n",
       "50%    2000.000000     0.241000     0.241000     0.241000     0.238000   \n",
       "75%    2005.000000     1.405000     1.409000     1.409000     1.409000   \n",
       "max    2010.000000    12.026000    12.026000    12.026000    12.026000   \n",
       "\n",
       "              Lag5       Volume        Today  \n",
       "count  1089.000000  1089.000000  1089.000000  \n",
       "mean      0.139893     1.574618     0.149899  \n",
       "std       2.361285     1.686636     2.356927  \n",
       "min     -18.195000     0.087465   -18.195000  \n",
       "25%      -1.166000     0.332022    -1.154000  \n",
       "50%       0.234000     1.002680     0.241000  \n",
       "75%       1.405000     2.053727     1.405000  \n",
       "max      12.026000     9.328214    12.026000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032289</td>\n",
       "      <td>-0.033390</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>-0.031128</td>\n",
       "      <td>-0.030519</td>\n",
       "      <td>0.841942</td>\n",
       "      <td>-0.032460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>-0.032289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.074853</td>\n",
       "      <td>0.058636</td>\n",
       "      <td>-0.071274</td>\n",
       "      <td>-0.008183</td>\n",
       "      <td>-0.064951</td>\n",
       "      <td>-0.075032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>-0.033390</td>\n",
       "      <td>-0.074853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.075721</td>\n",
       "      <td>0.058382</td>\n",
       "      <td>-0.072499</td>\n",
       "      <td>-0.085513</td>\n",
       "      <td>0.059167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>-0.030006</td>\n",
       "      <td>0.058636</td>\n",
       "      <td>-0.075721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.075396</td>\n",
       "      <td>0.060657</td>\n",
       "      <td>-0.069288</td>\n",
       "      <td>-0.071244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>-0.031128</td>\n",
       "      <td>-0.071274</td>\n",
       "      <td>0.058382</td>\n",
       "      <td>-0.075396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.075675</td>\n",
       "      <td>-0.061075</td>\n",
       "      <td>-0.007826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>-0.030519</td>\n",
       "      <td>-0.008183</td>\n",
       "      <td>-0.072499</td>\n",
       "      <td>0.060657</td>\n",
       "      <td>-0.075675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058517</td>\n",
       "      <td>0.011013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.841942</td>\n",
       "      <td>-0.064951</td>\n",
       "      <td>-0.085513</td>\n",
       "      <td>-0.069288</td>\n",
       "      <td>-0.061075</td>\n",
       "      <td>-0.058517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Today</th>\n",
       "      <td>-0.032460</td>\n",
       "      <td>-0.075032</td>\n",
       "      <td>0.059167</td>\n",
       "      <td>-0.071244</td>\n",
       "      <td>-0.007826</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.033078</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year      Lag1      Lag2      Lag3      Lag4      Lag5    Volume  \\\n",
       "Year    1.000000 -0.032289 -0.033390 -0.030006 -0.031128 -0.030519  0.841942   \n",
       "Lag1   -0.032289  1.000000 -0.074853  0.058636 -0.071274 -0.008183 -0.064951   \n",
       "Lag2   -0.033390 -0.074853  1.000000 -0.075721  0.058382 -0.072499 -0.085513   \n",
       "Lag3   -0.030006  0.058636 -0.075721  1.000000 -0.075396  0.060657 -0.069288   \n",
       "Lag4   -0.031128 -0.071274  0.058382 -0.075396  1.000000 -0.075675 -0.061075   \n",
       "Lag5   -0.030519 -0.008183 -0.072499  0.060657 -0.075675  1.000000 -0.058517   \n",
       "Volume  0.841942 -0.064951 -0.085513 -0.069288 -0.061075 -0.058517  1.000000   \n",
       "Today  -0.032460 -0.075032  0.059167 -0.071244 -0.007826  0.011013 -0.033078   \n",
       "\n",
       "           Today  \n",
       "Year   -0.032460  \n",
       "Lag1   -0.075032  \n",
       "Lag2    0.059167  \n",
       "Lag3   -0.071244  \n",
       "Lag4   -0.007826  \n",
       "Lag5    0.011013  \n",
       "Volume -0.033078  \n",
       "Today   1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data = weekly_data.select_dtypes(include=[\"number\"])\n",
    "correlation_matrix = numeric_data.corr()\n",
    "correlation_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Graphical Summaries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Pairplot to visualize relationships\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mpairplot(weekly_data, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "# Pairplot to visualize relationships\n",
    "sns.pairplot(weekly_data, hue=\"Direction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram for Volume\n",
    "weekly_data['Volume'].hist(bins=20, edgecolor='black')\n",
    "plt.title('Histogram of Volume')\n",
    "plt.xlabel('Volume')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"Direction\", y=\"Volume\", data=weekly_data)\n",
    "plt.title('Boxplot of Volume by Direction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- From the histogram, Volume is positively skewed, with most values concentrated near zero and fewer larger values. This indicates that trading volumes are typically low but occasionally spike.\n",
    "- The means and medians of Lag variables are close to zero, indicating they are centered around the mean with a relatively symmetrical distribution.\n",
    "- The standard deviations for Lag variables are similar, suggesting comparable levels of variability.\n",
    "- The Today variable, like the Lag variables, has a mean close to zero, suggesting that daily changes in returns tend to be small.\n",
    "- There are slightly more Up days (605) than Down days (484).\n",
    "- Volume has a relatively high positive correlation with Year (0.841), suggesting that trading volume has increased over time.\n",
    "- Other correlations with Volume are small, indicating weak relationships with other variables.\n",
    "- The scatterplots suggest no obvious separation of Up and Down directions based on the Lag variables. This indicates that these variables alone may not be strong predictors of market direction.\n",
    "\n",
    "**Conclusion**\n",
    "- The dataset shows clear trends in trading volume over time but weak relationships between lagged variables and daily returns (Today) or direction (Up/Down)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Use the full data set to perform a logistic regression with Direction as the response and the five lag variables plus Volume as predictors.**\n",
    "- Use the summary function to print the results. \n",
    "- Do any of the predictors appear to be statistically significant? If so, which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682441\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            Dir_numeric   No. Observations:                 1089\n",
      "Model:                          Logit   Df Residuals:                     1082\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Sun, 08 Dec 2024   Pseudo R-squ.:                0.006580\n",
      "Time:                        03:56:43   Log-Likelihood:                -743.18\n",
      "converged:                       True   LL-Null:                       -748.10\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1313\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2669      0.086      3.106      0.002       0.098       0.435\n",
      "Lag1          -0.0413      0.026     -1.563      0.118      -0.093       0.010\n",
      "Lag2           0.0584      0.027      2.175      0.030       0.006       0.111\n",
      "Lag3          -0.0161      0.027     -0.602      0.547      -0.068       0.036\n",
      "Lag4          -0.0278      0.026     -1.050      0.294      -0.080       0.024\n",
      "Lag5          -0.0145      0.026     -0.549      0.583      -0.066       0.037\n",
      "Volume        -0.0227      0.037     -0.616      0.538      -0.095       0.050\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Convert the response variable (Direction) to numeric\n",
    "weekly_data['Dir_numeric'] = weekly_data['Direction'].map({'Up': 1, 'Down': 0})\n",
    "\n",
    "# Define predictors and response\n",
    "X = weekly_data[['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
    "y = weekly_data['Dir_numeric']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model and print result\n",
    "logit_model = sm.Logit(y, X).fit()\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Significant Predictors***\n",
    "- *Constant:* The intercept is statistically significant `p-value = 0.002`. Its positive coefficient `0.2669` suggests a higher baseline likelihood of *Direction = Up.*\n",
    "- *Lag2:* is statistically significant `p-value = 0.030`. Its positive coefficient `0.0584` indicates that higher values of Lag2 increase the likelihood of *Direction = Up.*\n",
    "- *Other predictors* do not show strong evidence of association with Direction at the 5% significance level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Table:\n",
      "Truth       0    1\n",
      "Predicted         \n",
      "0          54  430\n",
      "1          48  557\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities and convert to binary predictions (threshold = 0.5)\n",
    "predicted_probs = logit_model.predict(X)\n",
    "predicted_classes = (predicted_probs > 0.5).astype(int)\n",
    "\n",
    "# Compute and Display the confusion table\n",
    "conf_matrix = confusion_table(y, predicted_classes)\n",
    "print(\"Confusion Table:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy: 0.5611\n"
     ]
    }
   ],
   "source": [
    "# Extract confusion matrix values\n",
    "true_negatives = conf_matrix.loc[0, 0]\n",
    "false_positives = conf_matrix.loc[0, 1]\n",
    "false_negatives = conf_matrix.loc[1, 0]\n",
    "true_positives = conf_matrix.loc[1, 1]\n",
    "\n",
    "# Compute and Print overall accuracy\n",
    "accuracy = (true_negatives + true_positives) / conf_matrix.values.sum()\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Components of the Confusion Matrix:**\n",
    "- *True Negatives:* `54`: The model correctly predicted \"Down\" (0) when the actual value was \"Down\".\n",
    "- *False Positives:* `430`: The model incorrectly predicted \"Up\" (1) when the actual value was \"Down\".\n",
    "- *False Negatives:* `48`: The model incorrectly predicted \"Down\" (0) when the actual value was \"Up\".\n",
    "- *True Positives:* `557`: The model correctly predicted \"Up\" (1) when the actual value was \"Up\".\n",
    "\n",
    "    ***Overal Accuracy:*** `0.5611` means the model correctly predicts the direction 56.11% of the time, which is just slightly better than random guessing (50%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Now fit the logistic regression model using a training data period from 1990 to 2008, with Lag2 as the only predictor.**\n",
    "- Compute the confusion matrix and the overall fraction of correct predictions for the held out data (that is, the data from 2009 and 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.685555\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            Dir_numeric   No. Observations:                  985\n",
      "Model:                          Logit   Df Residuals:                      983\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 08 Dec 2024   Pseudo R-squ.:                0.003076\n",
      "Time:                        03:56:43   Log-Likelihood:                -675.27\n",
      "converged:                       True   LL-Null:                       -677.35\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04123\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2033      0.064      3.162      0.002       0.077       0.329\n",
      "Lag2           0.0581      0.029      2.024      0.043       0.002       0.114\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training (19902008) and testing (20092010) sets\n",
    "train_data = weekly_data[weekly_data['Year'] <= 2008]\n",
    "test_data = weekly_data[weekly_data['Year'] > 2008]\n",
    "\n",
    "# Define predictors and response variable\n",
    "X_train = train_data[['Lag2']]\n",
    "y_train = train_data['Dir_numeric']\n",
    "\n",
    "X_test = test_data[['Lag2']]\n",
    "y_test = test_data['Dir_numeric']\n",
    "\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Fit the logistic regression model and print; training data\n",
    "logit_model = sm.Logit(y_train, X_train).fit()\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Test Data):\n",
      "Truth      0   1\n",
      "Predicted       \n",
      "0          9  34\n",
      "1          5  56\n",
      "\n",
      "Overall Accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "predicted_probs = logit_model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "predicted_classes = (predicted_probs > 0.5).astype(int)\n",
    "\n",
    "# Compute the confusion matrix for the test data\n",
    "conf_matrix = confusion_table(y_test, predicted_classes)\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"\\nConfusion Matrix (Test Data):\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute and display overall accuracy\n",
    "true_negatives = conf_matrix.loc[0, 0]\n",
    "false_positives = conf_matrix.loc[0, 1]\n",
    "false_negatives = conf_matrix.loc[1, 0]\n",
    "true_positives = conf_matrix.loc[1, 1]\n",
    "\n",
    "accuracy = (true_negatives + true_positives) / conf_matrix.values.sum()\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2: Decision Trees\n",
    "The data (Insurance.csv) contains 5822 real customer records. Each record consists of 86 variables, containing sociodemographic data (variables 1-43) and product ownership (variables 44-86). The sociodemographic data is derived from zip codes. All customers living in areas with the same zip code have the same sociodemographic attributes. Variable 86 (Purchase) indicates whether the customer purchased a caravan insurance policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "***(a) Use the data to build a decision tress with the following hyper parameters(criteria=gini, max_depth =4, min_samples_split=1000, min_samples_leaf=200).***\n",
    "  - Identify the feature that has the greatest influence on loan status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  MGODOV  \\\n",
       "0       33         1        3         2         8       0       5       1   \n",
       "1       37         1        2         2         8       1       4       1   \n",
       "2       37         1        2         2         8       0       4       2   \n",
       "\n",
       "   MGODGE  MRELGE  ...  APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  APLEZIER  \\\n",
       "0       3       7  ...         0        0        0       1        0         0   \n",
       "1       4       6  ...         0        0        0       1        0         0   \n",
       "2       4       3  ...         0        0        0       1        0         0   \n",
       "\n",
       "   AFIETS  AINBOED  ABYSTAND  Purchase  \n",
       "0       0        0         0        No  \n",
       "1       0        0         0        No  \n",
       "2       0        0         0        No  \n",
       "\n",
       "[3 rows x 86 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "insurance_data = pd.read_csv(r\"C:\\Users\\kevin\\OneDrive\\Desktop\\Strathmore\\Classes\\December 2024\\Machine Learning\\Notes\\5.3 Insurance.csv\")\n",
    "insurance_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MOSTYPE', 'MAANTHUI', 'MGEMOMV', 'MGEMLEEF', 'MOSHOOFD', 'MGODRK',\n",
       "       'MGODPR', 'MGODOV', 'MGODGE', 'MRELGE', 'MRELSA', 'MRELOV', 'MFALLEEN',\n",
       "       'MFGEKIND', 'MFWEKIND', 'MOPLHOOG', 'MOPLMIDD', 'MOPLLAAG', 'MBERHOOG',\n",
       "       'MBERZELF', 'MBERBOER', 'MBERMIDD', 'MBERARBG', 'MBERARBO', 'MSKA',\n",
       "       'MSKB1', 'MSKB2', 'MSKC', 'MSKD', 'MHHUUR', 'MHKOOP', 'MAUT1', 'MAUT2',\n",
       "       'MAUT0', 'MZFONDS', 'MZPART', 'MINKM30', 'MINK3045', 'MINK4575',\n",
       "       'MINK7512', 'MINK123M', 'MINKGEM', 'MKOOPKLA', 'PWAPART', 'PWABEDR',\n",
       "       'PWALAND', 'PPERSAUT', 'PBESAUT', 'PMOTSCO', 'PVRAAUT', 'PAANHANG',\n",
       "       'PTRACTOR', 'PWERKT', 'PBROM', 'PLEVEN', 'PPERSONG', 'PGEZONG',\n",
       "       'PWAOREG', 'PBRAND', 'PZEILPL', 'PPLEZIER', 'PFIETS', 'PINBOED',\n",
       "       'PBYSTAND', 'AWAPART', 'AWABEDR', 'AWALAND', 'APERSAUT', 'ABESAUT',\n",
       "       'AMOTSCO', 'AVRAAUT', 'AAANHANG', 'ATRACTOR', 'AWERKT', 'ABROM',\n",
       "       'ALEVEN', 'APERSONG', 'AGEZONG', 'AWAOREG', 'ABRAND', 'AZEILPL',\n",
       "       'APLEZIER', 'AFIETS', 'AINBOED', 'ABYSTAND', 'Purchase'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "     Feature  Importance\n",
      "46  PPERSAUT    0.568976\n",
      "0    MOSTYPE    0.268783\n",
      "58    PBRAND    0.108343\n",
      "36   MINKM30    0.031323\n",
      "8     MGODGE    0.016664\n",
      "..       ...         ...\n",
      "80   AZEILPL    0.000000\n",
      "81  APLEZIER    0.000000\n",
      "82    AFIETS    0.000000\n",
      "83   AINBOED    0.000000\n",
      "84  ABYSTAND    0.000000\n",
      "\n",
      "[85 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the features and target variable\n",
    "X = insurance_data.iloc[:, :-1]  # All columns except the last\n",
    "y = insurance_data.iloc[:, -1]  # Last column (target: Purchase)\n",
    "\n",
    "# Initialize the Decision Tree Classifier with specified hyperparameters and Fit model\n",
    "tree_model = DecisionTreeClassifier(\n",
    "    criterion='gini', \n",
    "    max_depth=4, \n",
    "    min_samples_split=1000, \n",
    "    min_samples_leaf=200, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tree_model.fit(X, y)\n",
    "# Display the feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': tree_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The feature with the greatest influence on loan status is: PPERSAUT\n",
      "\n",
      "Decision Tree Rules:\n",
      "|--- PPERSAUT <= 5.50\n",
      "|   |--- MINKM30 <= 2.50\n",
      "|   |   |--- MGODGE <= 3.50\n",
      "|   |   |   |--- class: No\n",
      "|   |   |--- MGODGE >  3.50\n",
      "|   |   |   |--- class: No\n",
      "|   |--- MINKM30 >  2.50\n",
      "|   |   |--- MBERARBG <= 1.50\n",
      "|   |   |   |--- class: No\n",
      "|   |   |--- MBERARBG >  1.50\n",
      "|   |   |   |--- MOSTYPE <= 30.50\n",
      "|   |   |   |   |--- class: No\n",
      "|   |   |   |--- MOSTYPE >  30.50\n",
      "|   |   |   |   |--- class: No\n",
      "|--- PPERSAUT >  5.50\n",
      "|   |--- MOSTYPE <= 8.50\n",
      "|   |   |--- class: No\n",
      "|   |--- MOSTYPE >  8.50\n",
      "|   |   |--- PBRAND <= 2.50\n",
      "|   |   |   |--- class: No\n",
      "|   |   |--- PBRAND >  2.50\n",
      "|   |   |   |--- class: No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify the feature with the greatest influence\n",
    "most_influential_feature = feature_importances.iloc[0]\n",
    "print(f\"\\nThe feature with the greatest influence on loan status is: {most_influential_feature['Feature']}\")\n",
    "\n",
    "# Visualize the tree structure\n",
    "tree_rules = export_text(tree_model, feature_names=list(X.columns))\n",
    "print(\"\\nDecision Tree Rules:\")\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(b) Apply bagging, random forests, and gradient boosting classifiers to the Insurance data. Be sure to fit the models on a training set and to evaluate their performance on a test set.***\n",
    "  - Briefly comment on their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Performance:\n",
      "Accuracy: 0.9210\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.94      0.98      0.96      1628\n",
      "         Yes       0.23      0.07      0.10       119\n",
      "\n",
      "    accuracy                           0.92      1747\n",
      "   macro avg       0.58      0.53      0.53      1747\n",
      "weighted avg       0.89      0.92      0.90      1747\n",
      "\n",
      "[[1601   27]\n",
      " [ 111    8]]\n",
      "\n",
      "Random Forest Classifier Performance:\n",
      "Accuracy: 0.8403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.96      0.86      0.91      1628\n",
      "         Yes       0.22      0.52      0.31       119\n",
      "\n",
      "    accuracy                           0.84      1747\n",
      "   macro avg       0.59      0.69      0.61      1747\n",
      "weighted avg       0.91      0.84      0.87      1747\n",
      "\n",
      "[[1406  222]\n",
      " [  57   62]]\n",
      "\n",
      "Gradient Boosting Classifier Performance:\n",
      "Accuracy: 0.9319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      1.00      0.96      1628\n",
      "         Yes       0.50      0.03      0.05       119\n",
      "\n",
      "    accuracy                           0.93      1747\n",
      "   macro avg       0.72      0.51      0.51      1747\n",
      "weighted avg       0.90      0.93      0.90      1747\n",
      "\n",
      "[[1625    3]\n",
      " [ 116    3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "bagging_model = BaggingClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, max_depth=4, class_weight='balanced',random_state=42)\n",
    "gradient_boosting_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "\n",
    "# Fit models to the training data\n",
    "bagging_model.fit(X_train, y_train)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "gradient_boosting_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models on the test data\n",
    "bagging_preds = bagging_model.predict(X_test)\n",
    "random_forest_preds = random_forest_model.predict(X_test)\n",
    "gradient_boosting_preds = gradient_boosting_model.predict(X_test)\n",
    "\n",
    "# Compute accuracy scores\n",
    "bagging_acc = accuracy_score(y_test, bagging_preds)\n",
    "random_forest_acc = accuracy_score(y_test, random_forest_preds)\n",
    "gradient_boosting_acc = accuracy_score(y_test, gradient_boosting_preds)\n",
    "\n",
    "# Print results\n",
    "print(\"Bagging Classifier Performance:\")\n",
    "print(f\"Accuracy: {bagging_acc:.4f}\")\n",
    "print(classification_report(y_test, bagging_preds))\n",
    "print(confusion_matrix(y_test, bagging_preds))\n",
    "\n",
    "print(\"\\nRandom Forest Classifier Performance:\")\n",
    "print(f\"Accuracy: {random_forest_acc:.4f}\")\n",
    "print(classification_report(y_test, random_forest_preds))\n",
    "print(confusion_matrix(y_test, random_forest_preds))\n",
    "\n",
    "print(\"\\nGradient Boosting Classifier Performance:\")\n",
    "print(f\"Accuracy: {gradient_boosting_acc:.4f}\")\n",
    "print(classification_report(y_test, gradient_boosting_preds))\n",
    "print(confusion_matrix(y_test, gradient_boosting_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "1. **Bagging Classifier:**\n",
    "  - *Overall Accuracy:* `92.1%`, primarily driven by excellent performance on the majority class (No).\n",
    "    - *Performance on No:* Precision: `94%`, Recall: `98%` - highly effective at correctly identifying No.\n",
    "    - *Performance on Yes:* Precision: `23%`, Recall: `7%` - struggles to identify the minority class (Yes), with frequent false negatives and false positives.\n",
    "  - *Conclusion:* Bagging struggles with class imbalance, as it mostly predicts the majority class.\n",
    "2. **Random Forest Classifier:**\n",
    "  - *Overall Accuracy:* `84.03%`, slightly lower than Bagging.\n",
    "    - *Performance on No:* Precision: `96%`, Recall: `86%` - slightly less effective at identifying No compared to Bagging.\n",
    "    - *Performance on Yes:* Precision: `22%`, Recall: `52%`- better than Bagging in identifying Yes, with improved recall but still low precision.\n",
    "  - *Conclusion:* Random Forest balances prediction for both classes better than Bagging but still struggles with precision for Yes.\n",
    "3. **Gradient Boosting Classifier:**\n",
    "  - *Overall Accuracy:* `93.19%`, the highest among the three models.\n",
    "    - *Performance on No:* Precision: `93%`, Recall: `100%` - perfectly identifies No cases.\n",
    "    - *Performance on Yes:* Precision: `50%`, Recall: `3%` - while precision is higher, recall is very poor, leading to frequent false negatives.\n",
    "  - *Conclusion:* Gradient Boosting overfits to the majority class, leading to poor recall for the minority class (Yes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2: Using the same data set as in Question 1 (the insurance.csv) answer the following questions.**\n",
    "\n",
    "***(a) Create a training set containing 70% of the data and 30% test data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5822, 86)\n",
      "Training set size: 4075 samples\n",
      "Test set size: 1747 samples\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(insurance_data.shape)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(b) Fit a support vector machine classifier (use a linear kernel function and choose a suitable value of C).***\n",
    "- What is the number of support vectors?        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors for each class: [1408  229]\n",
      "Total number of support vectors: 1637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the SVM classifier with a linear kernel and C=1.0 and fit model; training data\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve and print the number of support vectors for each class\n",
    "num_support_vectors = svm_model.n_support_\n",
    "print(f\"Number of support vectors for each class: {num_support_vectors}\")\n",
    "print(f\"Total number of support vectors: {num_support_vectors.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(c) Compute the training and test error rates for the kernel SVM in (ii).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error Rate: 0.0562\n",
      "Test Error Rate: 0.0681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Compute predictions\n",
    "y_train_pred = svm_model.predict(X_train)\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate the training and test error rates and print results\n",
    "train_error_rate = 1 - accuracy_score(y_train, y_train_pred)\n",
    "test_error_rate = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Error Rate: {train_error_rate:.4f}\")\n",
    "print(f\"Test Error Rate: {test_error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(d) Use GridSearchCV to select an optimal cost (C). Consider values in the range 0.01 to 10 in steps of 2.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Optimal C: 0.01\n",
      "Cross-validated Accuracy with Optimal C: 0.9438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for C values\n",
    "param_grid = {'C': [0.01, 0.1, 1, 3, 5, 7, 10]}\n",
    "\n",
    "# Initialize the SVM classifier with a linear kernel\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best C value and corresponding accuracy\n",
    "best_c = grid_search.best_params_['C']\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Optimal C: {best_c}\")\n",
    "print(f\"Cross-validated Accuracy with Optimal C: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(e) Compute the training and test error rate using this new value for cost***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error Rate with Optimal C: 0.0562\n",
      "Test Error Rate with Optimal C: 0.0681\n"
     ]
    }
   ],
   "source": [
    "# Refit the SVM model with the optimal C value\n",
    "optimal_svm_model = SVC(kernel='linear', C=best_c, random_state=42)\n",
    "optimal_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and test data\n",
    "y_train_pred = optimal_svm_model.predict(X_train)\n",
    "y_test_pred = optimal_svm_model.predict(X_test)\n",
    "\n",
    "# Calculate the training and test error rates\n",
    "train_error_rate = 1 - accuracy_score(y_train, y_train_pred)\n",
    "test_error_rate = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the error rates\n",
    "print(f\"Training Error Rate with Optimal C: {train_error_rate:.4f}\")\n",
    "print(f\"Test Error Rate with Optimal C: {test_error_rate:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
